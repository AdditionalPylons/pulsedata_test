{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d84bacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "22a98ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Can remove this import since it's no longer used\n",
    "# import pandas as pd\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import functions as sf, types, Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9ca2fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "12f97337",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_GROUPS_SCHEMA = types.StructType([\n",
    "    types.StructField(\"ICD_CODE\",types.StringType(),nullable=False),\n",
    "    types.StructField(\"GROUP\",types.StringType(),nullable=False),\n",
    "])\n",
    "\n",
    "DEMOGRAPHICS_SCHEMA = types.StructType([\n",
    "    types.StructField(\"CLINIC\",types.StringType(),nullable=True),\n",
    "    types.StructField(\"MRN\",types.StringType(),nullable=False),\n",
    "    types.StructField(\"FIRST_NAME\",types.StringType(),nullable=True),\n",
    "    types.StructField(\"LAST_NAME\",types.StringType(),nullable=True),\n",
    "    types.StructField(\"DATE_OF_BIRTH\",types.DateType(),nullable=False),\n",
    "])\n",
    "\n",
    "ENCOUNTERS_SCHEMA = types.StructType([\n",
    "    types.StructField(\"DATE\",types.DateType(),nullable=True),\n",
    "    types.StructField(\"ENC_ID\",types.StringType(),nullable=True),\n",
    "    types.StructField(\"MRN\",types.StringType(),nullable=False),\n",
    "    types.StructField(\"ICD_CODE\",types.StringType(),nullable=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "697cdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(path):\n",
    "    # Spark requires path as a str\n",
    "    path = str(path)\n",
    "\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    if filename.casefold() == \"code_groups\":\n",
    "        schema = CODE_GROUPS_SCHEMA\n",
    "    elif filename.casefold() == \"demographics\":\n",
    "        schema = DEMOGRAPHICS_SCHEMA\n",
    "    elif filename.casefold() == \"encounters\":\n",
    "        schema = ENCOUNTERS_SCHEMA\n",
    "\n",
    "    df = (\n",
    "        spark.read\n",
    "        .option(\"delimiter\", \"|\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(schema)\n",
    "        .csv(path)\n",
    "    )\n",
    "            \n",
    "    parquet_path = path.split(\".\")[0]+\".parquet\"\n",
    "\n",
    "    df.write.mode(\"overwrite\").parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "81c3f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    path = str(path)\n",
    "\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    if filename.casefold() == \"code_groups\":\n",
    "        schema = CODE_GROUPS_SCHEMA\n",
    "    elif filename.casefold() == \"demographics\":\n",
    "        schema = DEMOGRAPHICS_SCHEMA\n",
    "    elif filename.casefold() == \"encounters\":\n",
    "        schema = ENCOUNTERS_SCHEMA\n",
    "\n",
    "    df = (\n",
    "        spark.read\n",
    "        .option(\"delimiter\", \"|\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(schema)\n",
    "        .csv(path)\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "698a031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This can be rewritten to use Spark-native functions.\n",
    "# This removes a dependency we don't use otherwise\n",
    "def read_parquet(path):\n",
    "    path = str(path)\n",
    "\n",
    "    df = spark.read.parquet(path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e2ade5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(sdf, name_map):\n",
    "    for from_col, to_col in name_map.items():\n",
    "        sdf = sdf.withColumnRenamed(from_col, to_col)\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "153070a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_encounters(enc_sdf):\n",
    "    sdf2 = (\n",
    "        enc_sdf\n",
    "        .withColumn('ROW_ID', sf.monotonically_increasing_id())\n",
    "        .withColumn('PRIORITY', sf.row_number().over(Window.partitionBy('ENC_ID').orderBy('ROW_ID')))\n",
    "        .drop('ROW_ID')\n",
    "        .groupBy(['ENC_ID', 'DATE', 'MRN'])\n",
    "        .pivot('PRIORITY')\n",
    "        .agg(sf.first('ICD_CODE'))\n",
    "    )\n",
    "    return rename_columns(sdf2, {i: f'ICD_CODE_{i}' for i in sdf2.columns[3:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "50852b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bucket(age):\n",
    "    if age > 100:\n",
    "        return 100\n",
    "    elif age > 90:\n",
    "        return 90\n",
    "    elif age > 80:\n",
    "        return 90\n",
    "    elif age > 70:\n",
    "        return 70\n",
    "    elif age > 60:\n",
    "        return 60\n",
    "    elif age > 50:\n",
    "        return 50\n",
    "    elif age > 40:\n",
    "        return 40\n",
    "    else:\n",
    "        # ignore all patients under 40\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "339af312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to data_2, data_3 or data_4 to use a different dataset\n",
    "data_folder = pathlib.Path('data_4')\n",
    "\n",
    "code_groups = pathlib.Path('code_groups.csv')\n",
    "demographics = data_folder.joinpath('demographics.csv')\n",
    "encounters = data_folder.joinpath('encounters.csv')\n",
    "\n",
    "#for csv in [code_groups, demographics, encounters]:\n",
    "#    csv_to_parquet(csv)\n",
    "\n",
    "code_groups = pathlib.Path('code_groups.parquet')\n",
    "demographics = data_folder.joinpath('demographics.parquet')\n",
    "encounters = data_folder.joinpath('encounters.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4b5d882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_groups_sdf = read_parquet(code_groups)\n",
    "demo_sdf = read_parquet(demographics)\n",
    "enc_sdf = read_parquet(encounters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1fe1b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Duplicate Count|\n",
      "+---------------+\n",
      "|              0|\n",
      "+---------------+\n",
      "\n",
      "Null Counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+---------+-------------+\n",
      "|CLINIC|MRN|FIRST_NAME|LAST_NAME|DATE_OF_BIRTH|\n",
      "+------+---+----------+---------+-------------+\n",
      "|     0|  0|         0|        0|            0|\n",
      "+------+---+----------+---------+-------------+\n",
      "\n",
      "ENC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/18 21:25:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/04/18 21:25:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/04/18 21:25:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/04/18 21:25:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/04/18 21:25:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/04/18 21:25:21 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Duplicate Count|\n",
      "+---------------+\n",
      "|              0|\n",
      "+---------------+\n",
      "\n",
      "Null Counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 581:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---+--------+\n",
      "|DATE|ENC_ID|MRN|ICD_CODE|\n",
      "+----+------+---+--------+\n",
      "|   0|     0|  0|       0|\n",
      "+----+------+---+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data quality checks\n",
    "\n",
    "def check_dupes(df):\n",
    "    return (\n",
    "        df.groupBy(df.columns)\n",
    "        .count()\n",
    "        .where(sf.col(\"count\") > 1)\n",
    "        .select(sf.coalesce(sf.sum(\"count\"), sf.lit(0)))\n",
    "        .withColumnRenamed(\"coalesce(sum(count), 0)\", f\"Duplicate Count\")\n",
    "        .show()\n",
    "    )\n",
    "\n",
    "def check_nulls(df):\n",
    "    print(\"Null Counts\")\n",
    "    return df.select([sf.count(sf.when(sf.col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()\n",
    "\n",
    "def check_all(df):\n",
    "    check_dupes(df)\n",
    "    check_nulls(df)\n",
    "    #df.describe().show()\n",
    "\n",
    "print(\"DEMO\")\n",
    "check_all(demo_sdf)\n",
    "print(\"ENC\")\n",
    "check_all(enc_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7e3d0150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "enc_sdf = transform_encounters(enc_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c2a85008",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_sdf = demo_sdf.withColumn(\"FULL_MRN\", sf.concat(\"CLINIC\", \"MRN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "48aa1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sdf_added_cols = (\n",
    "    enc_sdf\n",
    "    .join(demo_sdf, enc_sdf.MRN == demo_sdf.FULL_MRN)\n",
    "    .withColumn('AGE', sf.datediff('DATE', 'DATE_OF_BIRTH') / 365)\n",
    "    .withColumn('AGE_BUCKET', sf.udf(age_bucket)(sf.col('AGE')))\n",
    "    .withColumn('ICD_CODE', sf.expr(\"stack(4, ICD_CODE_1, ICD_CODE_2, ICD_CODE_3, ICD_CODE_4)\"))\n",
    ")\n",
    "results = (\n",
    "    enc_sdf_added_cols\n",
    "    .join(code_groups_sdf, enc_sdf_added_cols.ICD_CODE==code_groups_sdf.ICD_CODE)\n",
    "    .groupBy('AGE_BUCKET', 'GROUP').count()\n",
    "    .withColumn(\n",
    "        '_row',\n",
    "        sf.row_number().over(Window().partitionBy(['AGE_BUCKET']).orderBy(sf.desc('count'))))\n",
    "    .filter(sf.col('_row') == 1)\n",
    "    .drop('_row')\n",
    "    .filter(sf.col('AGE_BUCKET') != 0)\n",
    "    .orderBy('AGE_BUCKET')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e762006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 592:=================================================>   (185 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------+\n",
      "|AGE_BUCKET|GROUP| count|\n",
      "+----------+-----+------+\n",
      "|       100|   10|149125|\n",
      "|        40|   10|111182|\n",
      "|        50|   10|111101|\n",
      "|        60|   10|111529|\n",
      "|        70|   10|111641|\n",
      "|        90|   10|221787|\n",
      "+----------+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f479aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
